{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "from utils import recursive_glob\n",
    "from augmentations import *\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import visdom\n",
    "import argparse\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "\n",
    "def setup_logging(name, filename=None):\n",
    "    FORMAT = '%(levelname)s %(filename)s:%(lineno)4d: %(message)s'\n",
    "    # Manually clear root loggers to prevent any module that may have called\n",
    "    # logging.basicConfig() from blocking our logging setup\n",
    "    logging.root.handlers = []\n",
    "    if filename is None:\n",
    "        logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
    "    else:\n",
    "        logging.basicConfig(level=logging.INFO, format=FORMAT, filename=filename)\n",
    "    logger = logging.getLogger(name)\n",
    "    return logger     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    logger = setup_logging(__name__, filename='./'+'DSACPose'+'.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image of size 804x244, with 1 channels.\n",
      "Use numpy.asarray to access buffer data.\n"
     ]
    }
   ],
   "source": [
    "print(rgbd_image.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSACPose(nn.Module):\n",
    "    '''\n",
    "    '''\n",
    "    def __init__(self, net_capacity):\n",
    "        super(DSACPose, self).__init__()\n",
    "\n",
    "        c = net_capacity\n",
    "        output_dim = 9 # rotation matrix ?\n",
    "\n",
    "        self.global_model = False\n",
    "\n",
    "        strides = [1, 2, 2, 2, 1, 1, 1]\n",
    "\n",
    "        # build network\n",
    "        self.conv1 = nn.Conv2d(4, 4*c, 3, strides[0], 1)\n",
    "        self.bn1 = nn.BatchNorm2d(4*c)\n",
    "        self.conv2 = nn.Conv2d(4*c, 8*c, 3, strides[1], 1)\n",
    "        self.bn2 = nn.BatchNorm2d(8*c)\n",
    "        self.conv3 = nn.Conv2d(8*c, 16*c, 3, strides[2], 1)\n",
    "        self.bn3 = nn.BatchNorm2d(16*c)\n",
    "        self.conv4 = nn.Conv2d(16*c, 32*c, 3, strides[3], 1)\n",
    "        self.bn4 = nn.BatchNorm2d(32*c)\n",
    "        self.conv5 = nn.Conv2d(32*c, 64*c, 3, strides[4], 1)\n",
    "        self.bn5 = nn.BatchNorm2d(64*c)\n",
    "        self.conv6 = nn.Conv2d(64*c, 64*c, 3, strides[5], 1)\n",
    "        self.bn6 = nn.BatchNorm2d(64*c)\n",
    "        self.conv7 = nn.Conv2d(64*c, 64*c, 3, strides[6], 1)\n",
    "        self.bn7 = nn.BatchNorm2d(64*c)\n",
    "\n",
    "        self.pool = nn.AdaptiveMaxPool2d(1) #used only for global models to support arbitrary image size\n",
    "        \n",
    "        self.fc1 = nn.Conv2d(64*c, 64*c, 1, 1, 0)\n",
    "        self.bn8 = nn.BatchNorm2d(64*c)\n",
    "        self.fc2 = nn.Conv2d(64*c, 64*c, 1, 1, 0)\n",
    "        self.bn9 = nn.BatchNorm2d(64*c)\n",
    "        self.fc3 = nn.Conv2d(64*c, output_dim, 1, 1, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass.\n",
    "        \n",
    "        input : 4D data tensor (BxCxHxW)\n",
    "        '''\n",
    "        batch_size = input.size(0)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(input)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        \n",
    "        #if self.global_model: x = self.pool(x)\n",
    "        \n",
    "        x = F.relu(self.bn8(self.fc1(x)))\n",
    "        x = F.relu(self.bn9(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSACPose(\n",
      "  (conv1): Conv2d(4, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv7): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): AdaptiveMaxPool2d(output_size=1)\n",
      "  (fc1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn9): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Conv2d(192, 9, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "torch.Size([10, 4, 244, 804]) torch.float32\n",
      "torch.Size([10, 9, 31, 101])\n"
     ]
    }
   ],
   "source": [
    "net = DSACPose(3)\n",
    "print(net)\n",
    "input = torch.randn(10, 4, 244, 804) # data, channel, w, h\n",
    "print(input.shape, input.dtype)\n",
    "output = net(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 9, 31, 101])\n"
     ]
    }
   ],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7460dfe85658c9c3efe0bad721f060d1d299aba534351e45cc8c832cfd0f3ec3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('moon': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
